{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "speech2cmd-covid_faq.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOx0XOpX+7RQqd6kfRm6Jdz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/toonday/CarND-Advanced-Lane-Lines/blob/master/notebooks/pre-deployment/speech2cmd_covid_faq.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXAht64hzO5B"
      },
      "source": [
        "# **PRE-DEPLOYMENT: speech2cmd-covid_faq**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8aNngFQOCEmY"
      },
      "source": [
        "import os\n",
        "import pkg_resources\n",
        "\n",
        "install_commands = [\n",
        "  \"pip uninstall torchvision -y\",\n",
        "  \"pip uninstall torch -y\",\n",
        "  \"pip uninstall torchtext -y\",\n",
        "  \"pip uninstall torchaudio -y\",\n",
        "  #\"pip install torchvision==0.8.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html\",\n",
        "  #\"pip install torch==1.7.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\",\n",
        "  #\"pip install torchvision==0.8.1\",\n",
        "  #\"pip install torch==1.7.0\",\n",
        "  \"pip install torchvision==0.8.1+cpu -f https://download.pytorch.org/whl/torch_stable.html\",\n",
        "  \"pip install torch==1.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\",\n",
        "  \"pip install torchtext==0.8.0\",\n",
        "  \"pip install torchaudio==0.7.0\",\n",
        "  \"pip install sentencepiece==0.1.91\",\n",
        "  \"pip install urllib3==1.25.11\",\n",
        "  \"pip install onnxruntime==1.5.2\",\n",
        "  \"pip install frozendict==1.2\",\n",
        "  \"pip install braceexpand==0.1.6\",\n",
        "  \"pip install editdistance==0.5.3\",\n",
        "  \"pip install inflect==4.1.0\",\n",
        "  \"pip install kaldi-io==0.9.4\",\n",
        "  \"pip install librosa==0.8.0\",\n",
        "  \"pip install marshmallow==3.9.1\",\n",
        "  \"pip install packaging==20.4\",\n",
        "  \"pip install num2words==0.5.10\",\n",
        "  \"pip install ruamel.yaml==0.16.12\",\n",
        "  \"pip install soundfile==0.10.3.post1\",\n",
        "  \"pip install sox==1.4.1\",\n",
        "  \"pip install torch-stft==0.1.4\",\n",
        "  \"pip install unidecode==1.1.1\",\n",
        "  \"pip install webdataset==0.1.40\",\n",
        "  \"pip install kaldi-python-io==1.1.3\",\n",
        "  \"pip install scipy==1.5.4\",\n",
        "  \"pip install pandas==1.1.4\",\n",
        "  \"pip install g2p_en==2.1.0\",\n",
        "  \"pip install nemo_toolkit==1.0.0b3\",\n",
        "  #\"pip install wget\",\n",
        "  #\"pip install gspread oauth2client df2gspread\",\n",
        "]\n",
        "\n",
        "required_pkgs = {'nemo-toolkit'}\n",
        "installed_pkgs = {pkg.key for pkg in pkg_resources.working_set}\n",
        "missing_pkgs = required_pkgs - installed_pkgs\n",
        "\n",
        "if missing_pkgs:\n",
        "  print(\"E no dey\")\n",
        "  for i in range(len(install_commands)):\n",
        "    os.system(install_commands[i])"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vM2MAEVGfQYd"
      },
      "source": [
        "# restart runtime"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "std8L-a84V2C"
      },
      "source": [
        ""
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-bbFB-6eoYsA"
      },
      "source": [
        "import os\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"]=\"/content/google-api-key-test-model-deploy.json\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78Rian9in_gY",
        "outputId": "b020201c-314f-4577-e126-26127fe7cf8c"
      },
      "source": [
        "%%bash \n",
        "echo $GOOGLE_APPLICATION_CREDENTIALS"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/google-api-key-test-model-deploy.json\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCD7xuAVaNso"
      },
      "source": [
        "from nemo.utils import logging as nemo_logging\n",
        "nemo_logging.setLevel(nemo_logging.ERROR)\n",
        "\n",
        "# Import general, miscellaneous and utility libraries\n",
        "import os\n",
        "import shutil\n",
        "import json\n",
        "import logging\n",
        "from google.cloud import storage\n",
        "\n",
        "import librosa\n",
        "\n",
        "import torch\n",
        "import nemo.collections.asr as nemo_asr\n",
        "from difflib import get_close_matches, SequenceMatcher\n",
        "\n",
        "\n",
        "# setup cloud storage varaibles\n",
        "storage_client = storage.Client()\n",
        "bucket_name = \"test-model-deploy.appspot.com\"\n",
        "storage_bucket = storage_client.bucket(bucket_name)\n",
        "cstorage_models_dpath = 'models/'\n",
        "cstorage_config_dpath = 'vai-service-config/voiceai-covid-faq/'\n",
        "\n",
        "# Set up paths for local directory\n",
        "#service_dpath = '/tmp/asr_service/' # for gcf deployment\n",
        "service_dpath = '/content/' # for colab testing\n",
        "config_dpath = service_dpath + 'config/'\n",
        "models_dpath = service_dpath + 'models/'\n",
        "audio_dpath = service_dpath + 'usr_data/'\n",
        "\n",
        "curr_state = None\n",
        "lang_code = None\n",
        "audio_fname = None\n",
        "\n",
        "service_option = None\n",
        "\n",
        "config_fnames = {\n",
        "  \"models\": \"map-models.json\",\n",
        "  \"cmd2digit\": \"map-cmd2digit.json\",\n",
        "  \"str2cmd\": \"map-str2cmd.json\",\n",
        "  \"thresh\": \"map-thresh.json\"\n",
        "}\n",
        "config_vars = {\n",
        "  \"models\": {},\n",
        "  \"cmd2digit\": {},\n",
        "  \"str2cmd\": {},\n",
        "  \"thresh\": {}\n",
        "}\n",
        "\n",
        "# ===================================\n",
        "# Functions to run model inference\n",
        "# ===================================\n",
        "def build_manifest(manifest_path, file_path, default_cmd):\n",
        "  with open(manifest_path, 'w') as fout:\n",
        "    duration = round(librosa.core.get_duration(filename=file_path), 2)\n",
        "\n",
        "    # Write the metadata to the manifest\n",
        "    metadata = {\n",
        "        \"audio_filepath\": file_path,\n",
        "        \"duration\": duration,\n",
        "        \"text\": default_cmd\n",
        "    }\n",
        "    json.dump(metadata, fout)\n",
        "    fout.write('\\n')\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def get_pred_str(model, dataloader, logprobs=False):\n",
        "  hypotheses = []\n",
        "\n",
        "  for batch in dataloader:\n",
        "    audio_signal, audio_signal_len, labels, labels_len = batch\n",
        "    logits, logits_len, greedy_predictions = model.forward(\n",
        "        input_signal=audio_signal, input_signal_length=audio_signal_len\n",
        "    )\n",
        "    if logprobs:\n",
        "        # dump log probs per file\n",
        "        for idx in range(logits.shape[0]):\n",
        "            hypotheses.append(logits[idx][: logits_len[idx]])\n",
        "    else:\n",
        "        hypotheses += model._wer.ctc_decoder_predictions_tensor(greedy_predictions)\n",
        " \n",
        "  return hypotheses\n",
        "\n",
        "\n",
        "# ===================================\n",
        "# Functions to speech command recognition service\n",
        "# ===================================\n",
        "def download_avail_models():\n",
        "  global storage_bucket\n",
        "  global models_dpath\n",
        "  global cstorage_models_dpath\n",
        "\n",
        "  if not os.path.isdir(models_dpath):\n",
        "    os.makedirs(models_dpath)\n",
        "\n",
        "  blob_list = storage_bucket.list_blobs(prefix=cstorage_models_dpath)\n",
        "  for blob in blob_list:\n",
        "    if blob.name != cstorage_models_dpath:\n",
        "      fname = blob.name.replace(cstorage_models_dpath, '')\n",
        "      model_fpath = models_dpath + fname\n",
        "      if not os.path.exists(model_fpath):\n",
        "        blob.download_to_filename(model_fpath)\n",
        "\n",
        "\n",
        "def clear_avail_models():\n",
        "  if os.path.isdir(models_dpath):\n",
        "    shutil.rmtree(models_dpath)\n",
        "\n",
        "\n",
        "def setup_service_config_vars():\n",
        "  global config_vars\n",
        "\n",
        "  if not os.path.isdir(audio_dpath):\n",
        "    os.makedirs(audio_dpath)\n",
        "\n",
        "  if not os.path.isdir(config_dpath):\n",
        "    os.makedirs(config_dpath)\n",
        "\n",
        "  blob_list = storage_bucket.list_blobs(prefix=cstorage_config_dpath)\n",
        "  for blob in blob_list:\n",
        "    if blob.name != cstorage_config_dpath:\n",
        "      fname = blob.name.replace(cstorage_config_dpath, '')\n",
        "      fpath = config_dpath + fname\n",
        "      if not os.path.exists(fpath):\n",
        "        blob.download_to_filename(fpath)\n",
        "  \n",
        "  for fname in config_fnames.values():\n",
        "    fpath = config_dpath + fname\n",
        "    if not os.path.exists(fpath):\n",
        "      assert False, \"All service configuration files are needed for service to be functional. Missing file '{}'\".format(fpath)\n",
        "  \n",
        "  for key in config_fnames.keys():\n",
        "    fpath = config_dpath + config_fnames[key]\n",
        "    with open(fpath) as f:\n",
        "      config_vars[key] = json.load(f)\n",
        "  \n",
        "  # ensure that the fname specified for each model exists\n",
        "  for key in config_vars[\"models\"].keys():\n",
        "    fpath = models_dpath + config_vars[\"models\"][key]\n",
        "    if not os.path.exists(fpath):\n",
        "      assert False, \"Specified model for language code '{}' does not exist. Missing file '{}'\".format(key, fpath)\n",
        "\n",
        "\n",
        "def clear_service_config_vars():\n",
        "  global config_vars\n",
        "  \n",
        "  if os.path.isdir(config_dpath):\n",
        "    shutil.rmtree(config_dpath)\n",
        "  \n",
        "  for key in config_vars.keys():\n",
        "    config_vars[key] = {}\n",
        "\n",
        "\n",
        "def speech_to_string():\n",
        "  global models_dpath\n",
        "  global audio_dpath\n",
        "  global audio_fname\n",
        "\n",
        "  model_fname = config_vars[\"models\"][lang_code]\n",
        "  model_fpath = models_dpath + model_fname\n",
        "  loaded_asr_model = nemo_asr.models.EncDecCTCModel.restore_from(restore_path=model_fpath)\n",
        "\n",
        "  audio_fpath = audio_dpath + audio_fname\n",
        "  manifest_fpath = service_dpath + \"manifest.json\"\n",
        "  build_manifest(manifest_fpath, audio_fpath, 'nothing')\n",
        "\n",
        "  dl_config = None\n",
        "  if 'test_ds' in loaded_asr_model.cfg.keys():\n",
        "    dl_config = loaded_asr_model.cfg.test_ds\n",
        "  else:\n",
        "    dl_config = loaded_asr_model.cfg.validation_ds\n",
        "  dl_config.manifest_filepath = manifest_fpath\n",
        "  \n",
        "  dl = loaded_asr_model._setup_dataloader_from_config(dl_config)\n",
        "  dl.dataset._sample_rate = dl_config.sample_rate\n",
        "  \n",
        "  cpu_model = loaded_asr_model.cpu()\n",
        "  cpu_model.eval()\n",
        "\n",
        "  pred_str = get_pred_str(cpu_model, dl)[0]\n",
        "\n",
        "  return pred_str\n",
        "\n",
        "\n",
        "def string_to_command(pred_str, curr_state):\n",
        "  class_options = config_vars[\"str2cmd\"][curr_state][lang_code]\n",
        "  conf_level = 0.0\n",
        "  percentile_bins = [0.8, 0.6, 0.4, 0.2]\n",
        "  \n",
        "  # remove space between characters seems algorithm seems to work a little better for the intended use-case of auditory (phonetic) similarity comparison rather than the original design character based comparison\n",
        "  options_aud = {}\n",
        "  for option in class_options.keys():\n",
        "    option_aud_str = option.replace(\" \", \"\")\n",
        "    options_aud[option_aud_str] = option\n",
        "  \n",
        "  closest_match = []\n",
        "  pred_aud_str = pred_str.replace(\" \", \"\")\n",
        "  for i in range(len(percentile_bins)):\n",
        "    closest_match = get_close_matches(pred_aud_str, options_aud, 1, percentile_bins[i])\n",
        "    if len(closest_match) > 0:\n",
        "      break\n",
        "\n",
        "  # calculate similarity between predicted string and closest match string and use that as the confidence level\n",
        "  conf_level = 0\n",
        "  pred_cmd = None\n",
        "  closest_match_aud_str = None if len(closest_match) <= 0 else closest_match[0]\n",
        "  closest_match_str = None if closest_match_aud_str == None else options_aud[closest_match_aud_str]\n",
        "  if closest_match_str != None:\n",
        "    ratio1 = SequenceMatcher(None, pred_aud_str, closest_match_aud_str).ratio()\n",
        "    ratio2 = SequenceMatcher(None, closest_match_aud_str, pred_aud_str).ratio()\n",
        "    conf_level = (ratio1 + ratio2) / 2.0\n",
        "    pred_cmd = class_options[closest_match_str]\n",
        "\n",
        "  return pred_cmd, closest_match_str, conf_level, pred_aud_str, closest_match_aud_str\n",
        "\n",
        "\n",
        "def command_to_digit(command, curr_state):\n",
        "  digit = -1\n",
        "  if command != None:\n",
        "    digit = config_vars[\"cmd2digit\"][curr_state][command]\n",
        "  \n",
        "  return digit\n",
        "\n",
        "\n",
        "def process_client_json(json_data):\n",
        "  global service_option\n",
        "  global curr_state\n",
        "  global lang_code\n",
        "  global audio_fname\n",
        "\n",
        "  status_obj = None\n",
        "\n",
        "  if not 'service_option' in json_data.keys():\n",
        "    status_obj = {\n",
        "      \"status\": \"error\",\n",
        "      \"message\": \"service_option attribute is expected to be specified to this endpoint\"\n",
        "    }\n",
        "    return status_obj\n",
        "  service_option = json_data['service_option']\n",
        "\n",
        "  # check if service_option has acceptable value and return error where appropriate\n",
        "  if not service_option in ['init', 'clear', 'pred', 'pred_cache_audio']:\n",
        "    status_obj = {\n",
        "      \"status\": \"error\",\n",
        "      \"message\": \"expecting  received incorrect setting {} for service option\".format(service_option)\n",
        "    }\n",
        "    return status_obj\n",
        "\n",
        "  # no need to do further processing if user just wants to initialize or clear the service\n",
        "  if service_option == 'init' or service_option == 'clear':\n",
        "    return status_obj\n",
        "  \n",
        "  # check to ensure that service has been initialized\n",
        "  if 0 in [len(config_vars[\"models\"].keys()), len(config_vars[\"str2cmd\"].keys()), len(config_vars[\"cmd2digit\"].keys())]:\n",
        "    status_obj = {\n",
        "      \"status\": \"error\",\n",
        "      \"message\": \"speech2cmd service has not been initialized\"\n",
        "    }\n",
        "    return status_obj\n",
        "  \n",
        "  if not 'curr_state' in json_data.keys():\n",
        "    status_obj = {\n",
        "      \"status\": \"error\",\n",
        "      \"message\": \"curr_state attribute is expected to be specified to this endpoint\"\n",
        "    }\n",
        "    return status_obj\n",
        "  curr_state = json_data['curr_state']\n",
        "  \n",
        "  if not 'lang_code' in json_data.keys():\n",
        "    status_obj = {\n",
        "      \"status\": \"error\",\n",
        "      \"message\": \"lang_code attribute is expected to be specified to this endpoint\"\n",
        "    }\n",
        "    return status_obj\n",
        "  lang_code = json_data['lang_code']\n",
        "  \n",
        "  # check to ensure lang_code specified by client is supported\n",
        "  if lang_code not in config_vars[\"models\"].keys():\n",
        "    status_obj = {\n",
        "      \"status\": \"error\",\n",
        "      \"message\": \"lang_code specified '{}' is not supported by available models\".format(lang_code)\n",
        "    }\n",
        "    return status_obj\n",
        "  \n",
        "  audio_fname = json_data['audio_fname']\n",
        "\n",
        "  return status_obj\n",
        "\n",
        "\n",
        "def process_client_request(request):\n",
        "  # get data fields from post command and check if there are any errors\n",
        "  data = request.form.to_dict()\n",
        "\n",
        "  if data['service_option'] in ['pred', 'pred_cache_audio']:\n",
        "    # get and save wav audio file to local tmp directory from post command\n",
        "    expected_num_of_files = 1\n",
        "    item_list = request.files.to_dict().items()\n",
        "    if len(item_list) != 1:\n",
        "      status_obj = {\n",
        "        \"status\": \"error\",\n",
        "        \"message\": \"expecting number of files to be {}, however, received {} instead\".format(expected_num_of_files, len(item_list))\n",
        "      }\n",
        "      return status_obj\n",
        "    \n",
        "    for item in item_list:\n",
        "      data['audio_fname'] = item[0]\n",
        "      audio_fcontent = item[1]\n",
        "\n",
        "      if not os.path.isdir(audio_dpath):\n",
        "        os.makedirs(audio_dpath)\n",
        "      audio_fpath = audio_dpath + data['audio_fname']\n",
        "      audio_fcontent.save(audio_fpath)\n",
        "  \n",
        "  return process_client_json(data)\n",
        "\n",
        "\n",
        "def handler_main(status_obj):\n",
        "  global storage_bucket\n",
        "  global service_option\n",
        "  global lang_code\n",
        "  global curr_state\n",
        "  global audio_dpath\n",
        "  global audio_fname\n",
        "  \n",
        "  return_headers = {\n",
        "    'Content-Type': 'application/json',\n",
        "    'Access-Control-Allow-Origin': '*'\n",
        "  }\n",
        "  if(status_obj):\n",
        "    return json.dumps(status_obj), 200, return_headers\n",
        "\n",
        "  if service_option == \"init\":\n",
        "    download_avail_models()\n",
        "    setup_service_config_vars()\n",
        "\n",
        "    status_obj = {\n",
        "      \"status\": \"success\",\n",
        "      \"message\": \"service successfully initialized\"\n",
        "    }\n",
        "    return json.dumps(status_obj), 200, return_headers\n",
        "  elif service_option == \"clear\":\n",
        "    clear_avail_models()\n",
        "    clear_service_config_vars()\n",
        "\n",
        "    status_obj = {\n",
        "      \"status\": \"success\",\n",
        "      \"message\": \"service files successfully cleared\"\n",
        "    }\n",
        "    return json.dumps(status_obj), 200, return_headers\n",
        "  elif service_option == \"pred\" or service_option == \"pred_cache_audio\":\n",
        "    pred_str = speech_to_string()\n",
        "    pred_cmd, match_str, confidence, pred_aud_str, match_aud_str = string_to_command(pred_str, curr_state)\n",
        "    action_digit = command_to_digit(pred_cmd, curr_state)\n",
        "    if confidence < config_vars[\"thresh\"][lang_code]:\n",
        "      action_digit = -1\n",
        "\n",
        "    audio_fpath = audio_dpath + audio_fname\n",
        "    if service_option == \"pred_cache_audio\":\n",
        "      dest_blob_name = \"data/usr_audio/\" + audio_fname\n",
        "      dest_blob = storage_bucket.blob(dest_blob_name)\n",
        "      dest_blob.upload_from_filename(audio_fpath)\n",
        "    \n",
        "    # comment line below if testing in colab and not gcf\n",
        "    # remove processed wav file from system\n",
        "    #os.remove(audio_fpath)\n",
        "    \n",
        "    lang_code = None\n",
        "    curr_state = None\n",
        "    status_obj = {\n",
        "      \"status\": \"success\",\n",
        "      \"message\": \"command prediction successfully made\",\n",
        "      \"pred_str\": pred_str,\n",
        "      \"match_str\": match_str,\n",
        "      \"pred_cmd\": pred_cmd,\n",
        "      \"confidence\": confidence,\n",
        "      \"action_digit\": action_digit,\n",
        "      \"pred_aud_str\": pred_aud_str,\n",
        "      \"match_aud_str\": match_aud_str\n",
        "    }\n",
        "    return json.dumps(status_obj), 200, return_headers\n",
        "\n",
        "\n",
        "def handler_json(json_data):\n",
        "  status_obj = process_client_json(json_data)\n",
        "  \n",
        "  return handler_main(status_obj)\n",
        "\n",
        "\n",
        "def handler(request):\n",
        "  status_obj = process_client_request(request)\n",
        "  \n",
        "  return handler_main(status_obj)\n",
        "\n"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ikbCoTUhKgF"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REajhHGBiMRa"
      },
      "source": [
        "**RUNNING Speech2Cmd E2E TESTS**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "206K9_IqhKjk",
        "outputId": "8b58a262-4854-4fea-f042-741665f93d23"
      },
      "source": [
        "print()\n",
        "print(\" =========== \")\n",
        "print(\" ... RUNNING Speech2Cmd E2E TESTS ... \")\n",
        "print(\" =========== \")\n",
        "print()\n",
        "\n",
        "results = []\n",
        "expected_results = []\n",
        "\n",
        "test_idx = 0\n",
        "\n",
        "\n",
        "test_idx += 1\n",
        "print()\n",
        "print()\n",
        "print(\"... TEST {} ...\".format(test_idx))\n",
        "print(\" ------------------------------------ \")\n",
        "res = handler_json({\n",
        "  \"service_option\": \"clear\"\n",
        "})\n",
        "results.append(json.loads(res[0]))\n",
        "expected_results.append({\n",
        "  \"status\": \"success\", \n",
        "  \"message\": \"service files successfully cleared\"\n",
        "})\n",
        "\n",
        "\n",
        "test_idx += 1\n",
        "print()\n",
        "print()\n",
        "print(\"... TEST {} ...\".format(test_idx))\n",
        "print(\" ------------------------------------ \")\n",
        "res = handler_json({\n",
        "  \"service_option\": \"pred\",\n",
        "  \"curr_state\": \"ASK_QUESTION\",\n",
        "  \"lang_code\": \"yor\",\n",
        "  \"audio_fname\": \"Recording #10.wav\"\n",
        "})\n",
        "results.append(json.loads(res[0]))\n",
        "expected_results.append({\n",
        "  \"status\": \"error\", \n",
        "  \"message\": \"speech2cmd service has not been initialized\"\n",
        "})\n",
        "\n",
        "\n",
        "test_idx += 1\n",
        "print()\n",
        "print()\n",
        "print(\"... TEST {} ...\".format(test_idx))\n",
        "print(\" ------------------------------------ \")\n",
        "res = handler_json({\n",
        "  \"service_option\": \"init\"\n",
        "})\n",
        "results.append(json.loads(res[0]))\n",
        "expected_results.append({\n",
        "  \"status\": \"success\", \n",
        "  \"message\": \"service successfully initialized\"\n",
        "})\n",
        "\n",
        "\n",
        "test_idx += 1\n",
        "print()\n",
        "print()\n",
        "print(\"... TEST {} ...\".format(test_idx))\n",
        "print(\" ------------------------------------ \")\n",
        "res = handler_json({\n",
        "  \"service_option\": \"pred\",\n",
        "  \"curr_state\": \"ASK_QUESTION\",\n",
        "  \"lang_code\": \"yor\",\n",
        "  \"audio_fname\": \"Recording #10.wav\"\n",
        "})\n",
        "results.append(json.loads(res[0]))\n",
        "expected_results.append({\n",
        "  \"status\": \"success\", \n",
        "  \"message\": \"command prediction successfully made\"\n",
        "})\n",
        "\n",
        "\n",
        "test_idx += 1\n",
        "print()\n",
        "print()\n",
        "print(\"... TEST {} ...\".format(test_idx))\n",
        "print(\" ------------------------------------ \")\n",
        "res = handler_json({\n",
        "  \"service_option\": \"pred\",\n",
        "  \"curr_state\": \"ASK_LANG_SELECT\",\n",
        "  \"lang_code\": \"eng\",\n",
        "  \"audio_fname\": \"Recording #15.wav\"\n",
        "})\n",
        "results.append(json.loads(res[0]))\n",
        "expected_results.append({\n",
        "  \"status\": \"success\", \n",
        "  \"message\": \"command prediction successfully made\"\n",
        "})\n",
        "\n",
        "\n",
        "test_idx += 1\n",
        "print()\n",
        "print()\n",
        "print(\"... TEST {} ...\".format(test_idx))\n",
        "print(\" ------------------------------------ \")\n",
        "res = handler_json({\n",
        "  \"service_option\": \"clear\"\n",
        "})\n",
        "results.append(json.loads(res[0]))\n",
        "expected_results.append({\n",
        "  \"status\": \"success\", \n",
        "  \"message\": \"service files successfully cleared\"\n",
        "})\n",
        "\n",
        "\n",
        "test_idx += 1\n",
        "print()\n",
        "print()\n",
        "print(\"... TEST {} ...\".format(test_idx))\n",
        "print(\" ------------------------------------ \")\n",
        "res = handler_json({\n",
        "  \"service_option\": \"pred\",\n",
        "  \"curr_state\": \"ASK_QUESTION\",\n",
        "  \"lang_code\": \"yor\",\n",
        "  \"audio_fname\": \"Recording #10.wav\"\n",
        "})\n",
        "results.append(json.loads(res[0]))\n",
        "expected_results.append({\n",
        "  \"status\": \"error\", \n",
        "  \"message\": \"speech2cmd service has not been initialized\"\n",
        "})\n"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            " =========== \n",
            " ... RUNNING Speech2Cmd E2E TESTS ... \n",
            " =========== \n",
            "\n",
            "\n",
            "\n",
            "... TEST 1 ...\n",
            " ------------------------------------ \n",
            "\n",
            "\n",
            "... TEST 2 ...\n",
            " ------------------------------------ \n",
            "\n",
            "\n",
            "... TEST 3 ...\n",
            " ------------------------------------ \n",
            "\n",
            "\n",
            "... TEST 4 ...\n",
            " ------------------------------------ \n",
            "\n",
            "\n",
            "... TEST 5 ...\n",
            " ------------------------------------ \n",
            "\n",
            "\n",
            "... TEST 6 ...\n",
            " ------------------------------------ \n",
            "\n",
            "\n",
            "... TEST 7 ...\n",
            " ------------------------------------ \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1gkLlfIPX9OA",
        "outputId": "d1a1e030-ee27-4c1a-cdcd-337bcbb7684d"
      },
      "source": [
        "\n",
        "test_passed = True\n",
        "for i in range(len(expected_results)):\n",
        "  if expected_results[i]['status'] != results[i]['status'] or expected_results[i]['message'] != results[i]['message']:\n",
        "    test_passed = False\n",
        "    break\n",
        "\n",
        "if test_passed:\n",
        "  print(\"E2E Speech2Cmd test passed - All tests passed sequentially as expected\")\n",
        "else:\n",
        "  print(\"E2E Speech2Cmd test failed - Test failed at idx: {} \".format(i))"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E2E Speech2Cmd test passed - All tests passed sequentially as expected\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8gyx-M0LeGRl",
        "outputId": "569cb090-0510-4d18-fa3f-5652b94e1ccd"
      },
      "source": [
        "print(json.dumps(results, indent=2, sort_keys=False))"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[\n",
            "  {\n",
            "    \"status\": \"success\",\n",
            "    \"message\": \"service files successfully cleared\"\n",
            "  },\n",
            "  {\n",
            "    \"status\": \"error\",\n",
            "    \"message\": \"speech2cmd service has not been initialized\"\n",
            "  },\n",
            "  {\n",
            "    \"status\": \"success\",\n",
            "    \"message\": \"service successfully initialized\"\n",
            "  },\n",
            "  {\n",
            "    \"status\": \"success\",\n",
            "    \"message\": \"command prediction successfully made\",\n",
            "    \"pred_str\": \"kinie cove nineteen\",\n",
            "    \"match_str\": \"k IH n iH k oH f iH d n aH iH n t IH n\",\n",
            "    \"pred_cmd\": \"basics\",\n",
            "    \"confidence\": 0.4,\n",
            "    \"action_digit\": 1,\n",
            "    \"pred_aud_str\": \"kiniecovenineteen\",\n",
            "    \"match_aud_str\": \"kIHniHkoHfiHdnaHiHntIHn\"\n",
            "  },\n",
            "  {\n",
            "    \"status\": \"success\",\n",
            "    \"message\": \"command prediction successfully made\",\n",
            "    \"pred_str\": \"peeg in\",\n",
            "    \"match_str\": \"p ih dz ih n\",\n",
            "    \"pred_cmd\": \"pidgin\",\n",
            "    \"confidence\": 0.42857142857142855,\n",
            "    \"action_digit\": 2,\n",
            "    \"pred_aud_str\": \"peegin\",\n",
            "    \"match_aud_str\": \"pihdzihn\"\n",
            "  },\n",
            "  {\n",
            "    \"status\": \"success\",\n",
            "    \"message\": \"service files successfully cleared\"\n",
            "  },\n",
            "  {\n",
            "    \"status\": \"error\",\n",
            "    \"message\": \"speech2cmd service has not been initialized\"\n",
            "  }\n",
            "]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc_4SL7KeGU6"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAXtYp6eio2T"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSNFXWgYio5v"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DzPx82Urh5yq",
        "outputId": "3ec70335-f37a-4e60-bf2d-143d69123c82"
      },
      "source": [
        "!wget --content-disposition https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_quartznet15x5/versions/1.0.0rc1/zip -O stt_en_quartznet15x5_1.0.0rc1.zip"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-22 07:40:44--  https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_quartznet15x5/versions/1.0.0rc1/zip\n",
            "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 13.56.52.101, 13.56.70.20\n",
            "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|13.56.52.101|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 \n",
            "Location: https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/nemo/models/stt_en_quartznet15x5/versions/1.0.0rc1/files.zip?response-content-disposition=attachment%3B%20filename%3D%22files.zip%22&response-content-type=application%2Fzip&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEAcaCXVzLXdlc3QtMSJIMEYCIQD9oeomL2fuXVWSBdohuCtCEHuLQr2xQvf%2B7vtdEbiIUwIhAPbtKfQs1VKRFhlayMX8ahNLbScq%2B3LiYMt6JuWehpB%2FKoMECND%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQAxoMNzg5MzYzMTM1MDI3IgwEx8PMWlZEvJniLJQq1wMGo0L88SBXP3PjLeNNpgk7WccuKcnOtcvDr3UlXu%2BWouw0Ev6L7SZsMXLhsy7uYMeuK2jojdPAQmFaAVslGM5%2BolEZZbyiSkeg74xGEwt0E2anEefpAFKbBXVJ9ugSWO0HQ1hhdv7fVJA4Fo%2BkmUIiNQZfAgfPZXfre%2F60JlMLH%2B9hLjWhugBn6oj0kQ7uFVe4NGQlz88ZpCtUAvm85A1lYi3rEebt5W1bHllPZu22ALC23Y%2BGy9szucfOmpmtAVNoK9KpcOR%2B6ls2ai1%2F410P3Hmn61XXV9xBEd0xdevtO9MIRkimglRy%2BTFAc6RZXfmr1CON5C5tzqXPqDLaT3AUW9D9rNxEwEEYYZGQJRt3iwJvhea9eXDJkrBOgiQ3CdTgmjB2hk0iN3shHCI2gS9pCwhUvV9E3cbp9GP0FKo6VgMK49SYWaQt7gOHTwcX5ZVcGBgRixCocXoN%2FVhajehCX%2Br3QvarcD90bz%2FoC7Wq%2BINo1nqt3ABzooBH27Gkf3L9qJY9atJhxzawOycTEZqCc4lM%2B6QPcZGEbec7CIoYAW8wPFG1z2FoFw8qkEoDGQPk7Wfius%2Bhb%2FIP7OuQfEWJKL4crrycWEN%2FH8AOhwVrqV6IEoU4uSYwsp3GhgY6pAFdeYA9WIweoaU50Nrq%2BHkHQYY17XLv5HAuLAjBtAgQaOAl1Bx2AC37OSD0xOX2QzstxnIobu8IgZM9Q9%2FZmpKbvlp0y34Mv1tzhOZv67WYz%2F9jah42RBTecjP12fTTCmqD%2BW2aSanHV7gQzFVQM6xxj5UPqxxw1ljrqHml9VGCfkv1kxWlMBA%2FmimWXwz9GScPRD4XKGPALUXaIRSJtDu1FnY3gw%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20210622T074044Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZ5GCYRR4F%2F20210622%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=dd048b444e54d785ff40eaca5dc8db15ed3061c6a502cc32464c65fa916fce66 [following]\n",
            "--2021-06-22 07:40:44--  https://prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com/org/nvidia/team/nemo/models/stt_en_quartznet15x5/versions/1.0.0rc1/files.zip?response-content-disposition=attachment%3B%20filename%3D%22files.zip%22&response-content-type=application%2Fzip&X-Amz-Security-Token=IQoJb3JpZ2luX2VjEAcaCXVzLXdlc3QtMSJIMEYCIQD9oeomL2fuXVWSBdohuCtCEHuLQr2xQvf%2B7vtdEbiIUwIhAPbtKfQs1VKRFhlayMX8ahNLbScq%2B3LiYMt6JuWehpB%2FKoMECND%2F%2F%2F%2F%2F%2F%2F%2F%2F%2FwEQAxoMNzg5MzYzMTM1MDI3IgwEx8PMWlZEvJniLJQq1wMGo0L88SBXP3PjLeNNpgk7WccuKcnOtcvDr3UlXu%2BWouw0Ev6L7SZsMXLhsy7uYMeuK2jojdPAQmFaAVslGM5%2BolEZZbyiSkeg74xGEwt0E2anEefpAFKbBXVJ9ugSWO0HQ1hhdv7fVJA4Fo%2BkmUIiNQZfAgfPZXfre%2F60JlMLH%2B9hLjWhugBn6oj0kQ7uFVe4NGQlz88ZpCtUAvm85A1lYi3rEebt5W1bHllPZu22ALC23Y%2BGy9szucfOmpmtAVNoK9KpcOR%2B6ls2ai1%2F410P3Hmn61XXV9xBEd0xdevtO9MIRkimglRy%2BTFAc6RZXfmr1CON5C5tzqXPqDLaT3AUW9D9rNxEwEEYYZGQJRt3iwJvhea9eXDJkrBOgiQ3CdTgmjB2hk0iN3shHCI2gS9pCwhUvV9E3cbp9GP0FKo6VgMK49SYWaQt7gOHTwcX5ZVcGBgRixCocXoN%2FVhajehCX%2Br3QvarcD90bz%2FoC7Wq%2BINo1nqt3ABzooBH27Gkf3L9qJY9atJhxzawOycTEZqCc4lM%2B6QPcZGEbec7CIoYAW8wPFG1z2FoFw8qkEoDGQPk7Wfius%2Bhb%2FIP7OuQfEWJKL4crrycWEN%2FH8AOhwVrqV6IEoU4uSYwsp3GhgY6pAFdeYA9WIweoaU50Nrq%2BHkHQYY17XLv5HAuLAjBtAgQaOAl1Bx2AC37OSD0xOX2QzstxnIobu8IgZM9Q9%2FZmpKbvlp0y34Mv1tzhOZv67WYz%2F9jah42RBTecjP12fTTCmqD%2BW2aSanHV7gQzFVQM6xxj5UPqxxw1ljrqHml9VGCfkv1kxWlMBA%2FmimWXwz9GScPRD4XKGPALUXaIRSJtDu1FnY3gw%3D%3D&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Date=20210622T074044Z&X-Amz-SignedHeaders=host&X-Amz-Expires=3600&X-Amz-Credential=ASIA3PSNVSIZ5GCYRR4F%2F20210622%2Fus-west-2%2Fs3%2Faws4_request&X-Amz-Signature=dd048b444e54d785ff40eaca5dc8db15ed3061c6a502cc32464c65fa916fce66\n",
            "Resolving prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)... 52.218.218.217\n",
            "Connecting to prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com (prod-model-registry-ngc-bucket.s3.us-west-2.amazonaws.com)|52.218.218.217|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 71014875 (68M) [application/zip]\n",
            "Saving to: ‘stt_en_quartznet15x5_1.0.0rc1.zip’\n",
            "\n",
            "stt_en_quartznet15x 100%[===================>]  67.72M  28.8MB/s    in 2.4s    \n",
            "\n",
            "2021-06-22 07:40:47 (28.8 MB/s) - ‘stt_en_quartznet15x5_1.0.0rc1.zip’ saved [71014875/71014875]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blB6GdHLh8co",
        "outputId": "582c3e61-ce11-433b-f212-d8b91d30eac8"
      },
      "source": [
        "!unzip stt_en_quartznet15x5_1.0.0rc1.zip"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  stt_en_quartznet15x5_1.0.0rc1.zip\n",
            "  inflating: stt_en_quartznet15x5.nemo  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Abzw9oO3pmKu",
        "outputId": "60c06ffa-c5a0-47cb-fe45-b8278d3a7bbf"
      },
      "source": [
        "!wget --content-disposition https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_quartznet15x5/versions/1.0.0b3/zip -O stt_en_quartznet15x5_1.0.0b3.zip"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-06-22 07:37:39--  https://api.ngc.nvidia.com/v2/models/nvidia/nemo/stt_en_quartznet15x5/versions/1.0.0b3/zip\n",
            "Resolving api.ngc.nvidia.com (api.ngc.nvidia.com)... 13.56.70.20, 13.56.52.101\n",
            "Connecting to api.ngc.nvidia.com (api.ngc.nvidia.com)|13.56.70.20|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 \n",
            "2021-06-22 07:37:39 ERROR 404: (no description).\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzzVkFcBi36r"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}